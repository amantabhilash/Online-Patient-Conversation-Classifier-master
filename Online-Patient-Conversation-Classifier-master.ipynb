{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the train and test Datasets\n",
    "train_dataset=pd.read_csv(r'C:\\Users\\Sonu\\Downloads\\datasetc062cf9\\dataset\\train.csv',encoding='ISO-8859-1')\n",
    "test_dataset=pd.read_csv(r'C:\\Users\\Sonu\\Downloads\\datasetc062cf9\\dataset\\test.csv',encoding= 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1157, 9)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Taking a look at the number of rows and columns of the datasets\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 10)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Source', 'Host', 'Link', 'Date(ET)', 'Time(ET)', 'time(GMT)', 'Title',\n",
       "       'TRANS_CONV_TEXT', 'Patient_Tag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring the column namespresent in the datasets\n",
    "train_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Source', 'Host', 'Link', 'Date(ET)', 'Time(ET)', 'time(GMT)',\n",
       "       'Title', 'TRANS_CONV_TEXT', 'Unnamed: 9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index Unnamed: 9\n",
       "0      1        NaN\n",
       "1      2        NaN\n",
       "2      3        NaN\n",
       "3      4        NaN\n",
       "4      5        NaN"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[['Index','Unnamed: 9']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the not so required columns 'Index' and 'Unnamed: 9' as they are not giving us any specific relevant information\n",
    "test_dataset.drop(columns= ['Index','Unnamed: 9'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Source', 'Host', 'Link', 'Date(ET)', 'Time(ET)', 'time(GMT)', 'Title',\n",
       "       'TRANS_CONV_TEXT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1157 entries, 0 to 1156\n",
      "Data columns (total 9 columns):\n",
      "Source             1157 non-null object\n",
      "Host               1098 non-null object\n",
      "Link               1157 non-null object\n",
      "Date(ET)           1157 non-null object\n",
      "Time(ET)           1157 non-null object\n",
      "time(GMT)          996 non-null object\n",
      "Title              941 non-null object\n",
      "TRANS_CONV_TEXT    1156 non-null object\n",
      "Patient_Tag        1157 non-null int64\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 81.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source               0\n",
       "Host                59\n",
       "Link                 0\n",
       "Date(ET)             0\n",
       "Time(ET)             0\n",
       "time(GMT)          161\n",
       "Title              216\n",
       "TRANS_CONV_TEXT      1\n",
       "Patient_Tag          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the single missing value in TRANS_CONV_TEXT, we apply imputation by mode to fill the value in\n",
    "train_dataset['TRANS_CONV_TEXT'] = train_dataset['TRANS_CONV_TEXT'].fillna(train_dataset['TRANS_CONV_TEXT'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source               0\n",
       "Host                59\n",
       "Link                 0\n",
       "Date(ET)             0\n",
       "Time(ET)             0\n",
       "time(GMT)          161\n",
       "Title              216\n",
       "TRANS_CONV_TEXT      0\n",
       "Patient_Tag          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifying no missing values in TRANS_CONV_TEXT\n",
    "train_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the values of  TRANS_CONV_TEXT and Patient_Tag and separating them out in a Dataframe\n",
    "New_train= train_dataset[['TRANS_CONV_TEXT','Patient_Tag']]\n",
    "New_test= test_dataset[['TRANS_CONV_TEXT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1157, 2)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1157.000000\n",
       "mean      1849.922213\n",
       "std       2324.023070\n",
       "min          2.000000\n",
       "25%        379.000000\n",
       "50%        963.000000\n",
       "75%       2441.000000\n",
       "max      16000.000000\n",
       "Name: TRANS_CONV_TEXT, dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_train['TRANS_CONV_TEXT'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      571.000000\n",
       "mean      1851.010508\n",
       "std       2399.454322\n",
       "min          3.000000\n",
       "25%        391.000000\n",
       "50%        971.000000\n",
       "75%       2530.000000\n",
       "max      16000.000000\n",
       "Name: TRANS_CONV_TEXT, dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_test['TRANS_CONV_TEXT'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    917\n",
       "1    240\n",
       "Name: Patient_Tag, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring distribution of Patient Tag\n",
    "New_train['Patient_Tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the train into another train and validation sets in 70:30 ratio respectively\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(New_train['TRANS_CONV_TEXT'], New_train['Patient_Tag'], \\\n",
    "                                                    test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to lower case\n",
    "\n",
    "New_train['TRANS_CONV_TEXT']=New_train['TRANS_CONV_TEXT'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "\n",
    "New_train['TRANS_CONV_TEXT']=New_train['TRANS_CONV_TEXT'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of digits\n",
    "\n",
    "from string import digits\n",
    "\n",
    "def remove_digits(s: str) -> str:\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    res = s.translate(remove_digits)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(remove_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying count vectorizer on the text\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=None,\n",
    "                             ngram_range=(1, 1), min_df=2, max_df=0.4, binary=True)\n",
    "\n",
    "train_features = vectorizer.fit_transform(X_train)\n",
    "train_labels = y_train\n",
    "\n",
    "valid_features = vectorizer.transform(X_valid)\n",
    "valid_labels = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95       274\n",
      "          1       0.82      0.76      0.79        74\n",
      "\n",
      "avg / total       0.91      0.91      0.91       348\n",
      "\n",
      "Accuracy:0.9137931034482759\n"
     ]
    }
   ],
   "source": [
    "#Applying Logistic regression\n",
    "model = LogisticRegression()\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "valid_preds = model.predict(valid_features)\n",
    "print(classification_report(valid_labels, valid_preds))\n",
    "print(f'Accuracy:{accuracy_score(valid_labels, valid_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93       274\n",
      "          1       0.75      0.74      0.75        74\n",
      "\n",
      "avg / total       0.89      0.89      0.89       348\n",
      "\n",
      "Accuracy:0.8936781609195402\n"
     ]
    }
   ],
   "source": [
    "#Applying XGBoost\n",
    "model = XGBClassifier()\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "valid_preds = model.predict(valid_features)\n",
    "print(classification_report(valid_labels, valid_preds))\n",
    "print(f'Accuracy:{accuracy_score(valid_labels, valid_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.93       274\n",
      "          1       0.70      0.89      0.79        74\n",
      "\n",
      "avg / total       0.91      0.90      0.90       348\n",
      "\n",
      "Accuracy:0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "#Applying Bernoulli's Naive Bayes\n",
    "model = BernoulliNB(fit_prior=True)\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "valid_preds = model.predict(valid_features)\n",
    "print(classification_report(valid_labels, valid_preds))\n",
    "print(f'Accuracy:{accuracy_score(valid_labels, valid_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.95      0.91       274\n",
      "          1       0.73      0.54      0.62        74\n",
      "\n",
      "avg / total       0.85      0.86      0.85       348\n",
      "\n",
      "Accuracy:0.8591954022988506\n"
     ]
    }
   ],
   "source": [
    "#Applying Random Forest Classifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "valid_preds = model.predict(valid_features)\n",
    "print(classification_report(valid_labels, valid_preds))\n",
    "print(f'Accuracy:{accuracy_score(valid_labels, valid_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make predictions and prepare the submissions file \n",
    "#Repeating the pre processing steps on the test dataset\n",
    "New_test['TRANS_CONV_TEXT'] = New_test['TRANS_CONV_TEXT'].apply(remove_digits)\n",
    "\n",
    "New_test['TRANS_CONV_TEXT'] = New_test['TRANS_CONV_TEXT'].str.lower()\n",
    "\n",
    "New_test['TRANS_CONV_TEXT'] = New_test['TRANS_CONV_TEXT'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = vectorizer.transform(New_test['TRANS_CONV_TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_submission = pd.read_csv(r'C:\\Users\\Sonu\\Downloads\\datasetc062cf9\\dataset\\test.csv',encoding= 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Index'] = test_for_submission['Index']\n",
    "submission['Patient_Tag'] = test_preds\n",
    "\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Patient_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index  Patient_Tag\n",
       "0       1            0\n",
       "1       2            1\n",
       "2       3            0\n",
       "3       4            0\n",
       "4       5            0\n",
       "5       6            0\n",
       "6       7            0\n",
       "7       8            1\n",
       "8       9            0\n",
       "9      10            0\n",
       "10     11            0\n",
       "11     12            0\n",
       "12     13            0\n",
       "13     14            0\n",
       "14     15            1"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
